{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-30T11:20:27.078120Z",
     "iopub.status.busy": "2023-06-30T11:20:27.077846Z",
     "iopub.status.idle": "2023-06-30T11:21:17.733709Z",
     "shell.execute_reply": "2023-06-30T11:21:17.732541Z",
     "shell.execute_reply.started": "2023-06-30T11:20:27.078095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Using cached imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\projects\\alzeimer\\alzheimer-s-disease-detection\\alzenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\projects\\alzeimer\\alzheimer-s-disease-detection\\alzenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in d:\\projects\\alzeimer\\alzheimer-s-disease-detection\\alzenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\projects\\alzeimer\\alzheimer-s-disease-detection\\alzenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\projects\\alzeimer\\alzheimer-s-disease-detection\\alzenv\\lib\\site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "#!pip install --upgrade numpy\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "            os.path.join(dirname, filename)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, RandomZoom, RandomFlip, RandomRotation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from distutils.dir_util import copy_tree, remove_tree\n",
    "!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:21:17.737016Z",
     "iopub.status.busy": "2023-06-30T11:21:17.735912Z",
     "iopub.status.idle": "2023-06-30T11:21:47.607749Z",
     "shell.execute_reply": "2023-06-30T11:21:47.606800Z",
     "shell.execute_reply.started": "2023-06-30T11:21:17.736983Z"
    }
   },
   "outputs": [
    {
     "ename": "DistutilsFileError",
     "evalue": "cannot copy tree '/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/': not a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDistutilsFileError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m     remove_tree(work_dir)\n\u001b[0;32m     11\u001b[0m os\u001b[39m.\u001b[39mmkdir(work_dir)\n\u001b[1;32m---> 12\u001b[0m copy_tree(train_dir, work_dir)\n\u001b[0;32m     13\u001b[0m copy_tree(test_dir, work_dir)\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWorking Directory Contents:\u001b[39m\u001b[39m\"\u001b[39m, os\u001b[39m.\u001b[39mlistdir(work_dir))\n",
      "File \u001b[1;32md:\\Projects\\Alzeimer\\Alzheimer-s-Disease-Detection\\alzenv\\lib\\site-packages\\setuptools\\_distutils\\dir_util.py:139\u001b[0m, in \u001b[0;36mcopy_tree\u001b[1;34m(src, dst, preserve_mode, preserve_times, preserve_symlinks, update, verbose, dry_run)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdistutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile_util\u001b[39;00m \u001b[39mimport\u001b[39;00m copy_file\n\u001b[0;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dry_run \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(src):\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mraise\u001b[39;00m DistutilsFileError(\u001b[39m\"\u001b[39m\u001b[39mcannot copy tree \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: not a directory\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m src)\n\u001b[0;32m    140\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     names \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(src)\n",
      "\u001b[1;31mDistutilsFileError\u001b[0m: cannot copy tree '/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/': not a directory"
     ]
    }
   ],
   "source": [
    "base_dir = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/\"\n",
    "root_dir = \"./\"\n",
    "test_dir = base_dir + \"test/\"\n",
    "train_dir = base_dir + \"train/\"\n",
    "work_dir = root_dir + \"dataset/\"\n",
    "\n",
    "if os.path.exists(work_dir):\n",
    "    remove_tree(work_dir)\n",
    "    \n",
    "\n",
    "os.mkdir(work_dir)\n",
    "copy_tree(train_dir, work_dir)\n",
    "copy_tree(test_dir, work_dir)\n",
    "print(\"Working Directory Contents:\", os.listdir(work_dir))\n",
    "\n",
    "WORK_DIR = './dataset/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:21:47.609305Z",
     "iopub.status.busy": "2023-06-30T11:21:47.608992Z",
     "iopub.status.idle": "2023-06-30T11:21:47.618053Z",
     "shell.execute_reply": "2023-06-30T11:21:47.617236Z",
     "shell.execute_reply.started": "2023-06-30T11:21:47.609280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NonDemented', 'MildDemented', 'VeryMildDemented', 'ModerateDemented']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.listdir(WORK_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:21:47.620334Z",
     "iopub.status.busy": "2023-06-30T11:21:47.620074Z",
     "iopub.status.idle": "2023-06-30T11:21:56.706650Z",
     "shell.execute_reply": "2023-06-30T11:21:56.705780Z",
     "shell.execute_reply.started": "2023-06-30T11:21:47.620311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: \n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 8\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "    \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:21:56.708170Z",
     "iopub.status.busy": "2023-06-30T11:21:56.707733Z",
     "iopub.status.idle": "2023-06-30T11:21:57.662914Z",
     "shell.execute_reply": "2023-06-30T11:21:57.661828Z",
     "shell.execute_reply.started": "2023-06-30T11:21:56.708133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, RandomZoom, RandomFlip, RandomRotation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IMG_SIZE = 176\n",
    "IMAGE_SIZE = [176, 176]\n",
    "DIM = (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "# Create the data augmentation pipeline\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    Rescaling(1./255),\n",
    "    RandomZoom(0.2),\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.2)\n",
    "])\n",
    "\n",
    "# Load images and apply data augmentation\n",
    "train_data_gen = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=WORK_DIR,\n",
    "    image_size=DIM,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "labels=\"inferred\"\n",
    ")\n",
    "\n",
    "train_data_augmented = train_data_gen.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:21:57.664554Z",
     "iopub.status.busy": "2023-06-30T11:21:57.664241Z",
     "iopub.status.idle": "2023-06-30T11:22:46.335047Z",
     "shell.execute_reply": "2023-06-30T11:22:46.333681Z",
     "shell.execute_reply.started": "2023-06-30T11:21:57.664526Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for data, labels in train_data_augmented:\n",
    "    train_data.append(data)\n",
    "    train_labels.append(labels)\n",
    "\n",
    "train_data = tf.concat(train_data, axis=0)\n",
    "train_labels = tf.concat(train_labels, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:22:46.337041Z",
     "iopub.status.busy": "2023-06-30T11:22:46.336688Z",
     "iopub.status.idle": "2023-06-30T11:22:46.342976Z",
     "shell.execute_reply": "2023-06-30T11:22:46.341818Z",
     "shell.execute_reply.started": "2023-06-30T11:22:46.337012Z"
    }
   },
   "outputs": [],
   "source": [
    "num_samples = train_data.shape[0]\n",
    "train_data_2d = tf.reshape(train_data, (num_samples, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:22:46.344540Z",
     "iopub.status.busy": "2023-06-30T11:22:46.344252Z",
     "iopub.status.idle": "2023-06-30T11:22:46.356148Z",
     "shell.execute_reply": "2023-06-30T11:22:46.355145Z",
     "shell.execute_reply.started": "2023-06-30T11:22:46.344515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform over-sampling of the data using SMOTE\n",
    "\n",
    "# Apply SMOTE-IMG\n",
    "smote_img = SMOTE(sampling_strategy='minority')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:22:46.357593Z",
     "iopub.status.busy": "2023-06-30T11:22:46.357320Z",
     "iopub.status.idle": "2023-06-30T11:23:18.969140Z",
     "shell.execute_reply": "2023-06-30T11:23:18.967795Z",
     "shell.execute_reply.started": "2023-06-30T11:22:46.357570Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data_resampled, train_labels_resampled = smote_img.fit_resample(train_data_2d, train_labels)\n",
    "\n",
    "# Reshape train_data_resampled back to 4D\n",
    "train_data_resampled = train_data_resampled.reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:23:18.972994Z",
     "iopub.status.busy": "2023-06-30T11:23:18.972663Z",
     "iopub.status.idle": "2023-06-30T11:23:18.979608Z",
     "shell.execute_reply": "2023-06-30T11:23:18.978825Z",
     "shell.execute_reply.started": "2023-06-30T11:23:18.972965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9536, 176, 176, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:23:18.980968Z",
     "iopub.status.busy": "2023-06-30T11:23:18.980677Z",
     "iopub.status.idle": "2023-06-30T11:23:20.829637Z",
     "shell.execute_reply": "2023-06-30T11:23:20.828440Z",
     "shell.execute_reply.started": "2023-06-30T11:23:18.980943Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Split the augmented data into train and test sets\n",
    "train_data1, test_data1, train_labels1, test_labels1 = train_test_split(train_data_resampled, train_labels_resampled, test_size=0.2, random_state=42,stratify=train_labels_resampled)\n",
    "\n",
    "# Further split the train set into train and validation sets\n",
    "train_data1, val_data1, train_labels1, val_labels1 = train_test_split(train_data1, train_labels1, test_size=0.2, random_state=42,stratify=train_labels1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:23:20.831114Z",
     "iopub.status.busy": "2023-06-30T11:23:20.830833Z",
     "iopub.status.idle": "2023-06-30T11:23:20.836092Z",
     "shell.execute_reply": "2023-06-30T11:23:20.835148Z",
     "shell.execute_reply.started": "2023-06-30T11:23:20.831090Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels1 = to_categorical(train_labels1)\n",
    "val_labels1 = to_categorical(val_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Name_of_the_classes = train_labels1\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for image_batch, labels_batch in train_data1.take(1):\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.numpy())\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(4, 3, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(Name_of_the_classes[labels_batch[i]])\n",
    "        plt.imshow(image_batch[i].numpy().astype('uint8'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:23:20.837674Z",
     "iopub.status.busy": "2023-06-30T11:23:20.837356Z",
     "iopub.status.idle": "2023-06-30T11:23:20.849855Z",
     "shell.execute_reply": "2023-06-30T11:23:20.849080Z",
     "shell.execute_reply.started": "2023-06-30T11:23:20.837648Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D()\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    return block\n",
    "\n",
    "def dense_block(units, dropout_rate):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:23:20.851163Z",
     "iopub.status.busy": "2023-06-30T11:23:20.850895Z",
     "iopub.status.idle": "2023-06-30T11:23:20.860303Z",
     "shell.execute_reply": "2023-06-30T11:23:20.859552Z",
     "shell.execute_reply.started": "2023-06-30T11:23:20.851139Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(IMAGE_SIZE[0],IMAGE_SIZE[1], 3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        \n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        \n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(4,activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:23:20.861572Z",
     "iopub.status.busy": "2023-06-30T11:23:20.861305Z",
     "iopub.status.idle": "2023-06-30T11:23:24.833211Z",
     "shell.execute_reply": "2023-06-30T11:23:24.832270Z",
     "shell.execute_reply.started": "2023-06-30T11:23:20.861549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 176, 176, 16)      448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 176, 176, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 88, 88, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 44, 44, 32)        2160      \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 22, 22, 64)        7392      \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 11, 11, 128)       27072     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 5, 5, 256)         103296    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 512)               3279360   \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 128)               66176     \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 64)                8512      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,496,996\n",
      "Trainable params: 3,494,628\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "\n",
    "    METRICS = [tf.keras.metrics.AUC(name='auc')]\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.losses.CategoricalCrossentropy()\n",
    "        ,\n",
    "        metrics=METRICS\n",
    "    )\n",
    "    \n",
    "    \n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:23:24.834638Z",
     "iopub.status.busy": "2023-06-30T11:23:24.834344Z",
     "iopub.status.idle": "2023-06-30T11:23:24.841213Z",
     "shell.execute_reply": "2023-06-30T11:23:24.840411Z",
     "shell.execute_reply.started": "2023-06-30T11:23:24.834611Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.01, 20)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\",\n",
    "                                                    save_best_only=True)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:23:24.842497Z",
     "iopub.status.busy": "2023-06-30T11:23:24.842233Z",
     "iopub.status.idle": "2023-06-30T11:31:32.699697Z",
     "shell.execute_reply": "2023-06-30T11:31:32.698075Z",
     "shell.execute_reply.started": "2023-06-30T11:23:24.842474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 11:23:37.903834: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add_100/ReadVariableOp.\n",
      "2023-06-30 11:23:38.151197: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add_100/ReadVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - ETA: 0s - loss: 1.4016 - auc: 0.6191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 11:24:05.327104: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\n",
      "2023-06-30 11:24:05.454530: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 44s 125ms/step - loss: 1.4016 - auc: 0.6191 - val_loss: 1.3795 - val_auc: 0.6471 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.2883 - auc: 0.6682 - val_loss: 1.4164 - val_auc: 0.6072 - lr: 0.0089\n",
      "Epoch 3/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.2636 - auc: 0.6859 - val_loss: 28.3331 - val_auc: 0.5577 - lr: 0.0079\n",
      "Epoch 4/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.2575 - auc: 0.6900 - val_loss: 1.2757 - val_auc: 0.6770 - lr: 0.0071\n",
      "Epoch 5/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.2341 - auc: 0.7079 - val_loss: 2.3195 - val_auc: 0.6164 - lr: 0.0063\n",
      "Epoch 6/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.1987 - auc: 0.7315 - val_loss: 6.6321 - val_auc: 0.5622 - lr: 0.0056\n",
      "Epoch 7/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.1929 - auc: 0.7344 - val_loss: 3.4454 - val_auc: 0.5427 - lr: 0.0050\n",
      "Epoch 8/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.1939 - auc: 0.7341 - val_loss: 28.0110 - val_auc: 0.5599 - lr: 0.0045\n",
      "Epoch 9/100\n",
      "191/191 [==============================] - 6s 30ms/step - loss: 1.1844 - auc: 0.7378 - val_loss: 1.3132 - val_auc: 0.6970 - lr: 0.0040\n",
      "Epoch 10/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.1891 - auc: 0.7362 - val_loss: 1.1783 - val_auc: 0.7460 - lr: 0.0035\n",
      "Epoch 11/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.1490 - auc: 0.7573 - val_loss: 1.1935 - val_auc: 0.7470 - lr: 0.0032\n",
      "Epoch 12/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.1205 - auc: 0.7727 - val_loss: 1.4097 - val_auc: 0.6151 - lr: 0.0028\n",
      "Epoch 13/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.1107 - auc: 0.7772 - val_loss: 1.1914 - val_auc: 0.7467 - lr: 0.0025\n",
      "Epoch 14/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0959 - auc: 0.7826 - val_loss: 1.5973 - val_auc: 0.6865 - lr: 0.0022\n",
      "Epoch 15/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0884 - auc: 0.7858 - val_loss: 1.8034 - val_auc: 0.5359 - lr: 0.0020\n",
      "Epoch 16/100\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 1.0823 - auc: 0.7877 - val_loss: 1.9600 - val_auc: 0.5148 - lr: 0.0018\n",
      "Epoch 17/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0772 - auc: 0.7910 - val_loss: 2.8755 - val_auc: 0.4010 - lr: 0.0016\n",
      "Epoch 18/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.1352 - auc: 0.7651 - val_loss: 1.1394 - val_auc: 0.7613 - lr: 0.0014\n",
      "Epoch 19/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.1066 - auc: 0.7774 - val_loss: 1.1657 - val_auc: 0.7548 - lr: 0.0013\n",
      "Epoch 20/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0911 - auc: 0.7839 - val_loss: 1.8095 - val_auc: 0.7048 - lr: 0.0011\n",
      "Epoch 21/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0840 - auc: 0.7886 - val_loss: 1.1968 - val_auc: 0.7726 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "191/191 [==============================] - 6s 30ms/step - loss: 1.0703 - auc: 0.7937 - val_loss: 9.3913 - val_auc: 0.6989 - lr: 8.9125e-04\n",
      "Epoch 23/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.1060 - auc: 0.7789 - val_loss: 25.8519 - val_auc: 0.5574 - lr: 7.9433e-04\n",
      "Epoch 24/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0792 - auc: 0.7906 - val_loss: 2.0485 - val_auc: 0.7253 - lr: 7.0795e-04\n",
      "Epoch 25/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0731 - auc: 0.7928 - val_loss: 0.9780 - val_auc: 0.8304 - lr: 6.3096e-04\n",
      "Epoch 26/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0653 - auc: 0.7967 - val_loss: 0.9478 - val_auc: 0.8441 - lr: 5.6234e-04\n",
      "Epoch 27/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0771 - auc: 0.7924 - val_loss: 0.9439 - val_auc: 0.8452 - lr: 5.0119e-04\n",
      "Epoch 28/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0552 - auc: 0.8005 - val_loss: 1.1152 - val_auc: 0.7524 - lr: 4.4668e-04\n",
      "Epoch 29/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0570 - auc: 0.7996 - val_loss: 1.0739 - val_auc: 0.7775 - lr: 3.9811e-04\n",
      "Epoch 30/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0467 - auc: 0.8043 - val_loss: 0.9629 - val_auc: 0.8376 - lr: 3.5481e-04\n",
      "Epoch 31/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0373 - auc: 0.8075 - val_loss: 0.9457 - val_auc: 0.8459 - lr: 3.1623e-04\n",
      "Epoch 32/100\n",
      "191/191 [==============================] - 6s 33ms/step - loss: 1.0420 - auc: 0.8059 - val_loss: 0.8929 - val_auc: 0.8602 - lr: 2.8184e-04\n",
      "Epoch 33/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0300 - auc: 0.8109 - val_loss: 0.9128 - val_auc: 0.8563 - lr: 2.5119e-04\n",
      "Epoch 34/100\n",
      "191/191 [==============================] - 6s 33ms/step - loss: 1.0349 - auc: 0.8085 - val_loss: 0.8923 - val_auc: 0.8578 - lr: 2.2387e-04\n",
      "Epoch 35/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0249 - auc: 0.8125 - val_loss: 0.8768 - val_auc: 0.8607 - lr: 1.9953e-04\n",
      "Epoch 36/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0231 - auc: 0.8128 - val_loss: 0.9945 - val_auc: 0.8113 - lr: 1.7783e-04\n",
      "Epoch 37/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.0239 - auc: 0.8130 - val_loss: 0.8830 - val_auc: 0.8585 - lr: 1.5849e-04\n",
      "Epoch 38/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0171 - auc: 0.8158 - val_loss: 0.8663 - val_auc: 0.8663 - lr: 1.4125e-04\n",
      "Epoch 39/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0064 - auc: 0.8206 - val_loss: 0.8615 - val_auc: 0.8665 - lr: 1.2589e-04\n",
      "Epoch 40/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0163 - auc: 0.8166 - val_loss: 0.8600 - val_auc: 0.8697 - lr: 1.1220e-04\n",
      "Epoch 41/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.0207 - auc: 0.8136 - val_loss: 0.8714 - val_auc: 0.8657 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 1.0092 - auc: 0.8186 - val_loss: 0.8663 - val_auc: 0.8673 - lr: 8.9125e-05\n",
      "Epoch 43/100\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 1.0158 - auc: 0.8160 - val_loss: 0.8686 - val_auc: 0.8657 - lr: 7.9433e-05\n",
      "Epoch 44/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0083 - auc: 0.8197 - val_loss: 0.8558 - val_auc: 0.8691 - lr: 7.0795e-05\n",
      "Epoch 45/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0059 - auc: 0.8201 - val_loss: 0.8597 - val_auc: 0.8689 - lr: 6.3096e-05\n",
      "Epoch 46/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0148 - auc: 0.8170 - val_loss: 0.8719 - val_auc: 0.8629 - lr: 5.6234e-05\n",
      "Epoch 47/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0046 - auc: 0.8210 - val_loss: 0.8735 - val_auc: 0.8626 - lr: 5.0119e-05\n",
      "Epoch 48/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 0.9959 - auc: 0.8231 - val_loss: 0.8591 - val_auc: 0.8673 - lr: 4.4668e-05\n",
      "Epoch 49/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0164 - auc: 0.8159 - val_loss: 0.8538 - val_auc: 0.8693 - lr: 3.9811e-05\n",
      "Epoch 50/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0087 - auc: 0.8189 - val_loss: 0.8532 - val_auc: 0.8703 - lr: 3.5481e-05\n",
      "Epoch 51/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.0066 - auc: 0.8194 - val_loss: 0.8543 - val_auc: 0.8701 - lr: 3.1623e-05\n",
      "Epoch 52/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.0049 - auc: 0.8196 - val_loss: 0.8566 - val_auc: 0.8693 - lr: 2.8184e-05\n",
      "Epoch 53/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.0149 - auc: 0.8175 - val_loss: 0.8562 - val_auc: 0.8693 - lr: 2.5119e-05\n",
      "Epoch 54/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 0.9980 - auc: 0.8234 - val_loss: 0.8537 - val_auc: 0.8703 - lr: 2.2387e-05\n",
      "Epoch 55/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.0063 - auc: 0.8207 - val_loss: 0.8551 - val_auc: 0.8693 - lr: 1.9953e-05\n",
      "Epoch 56/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.0076 - auc: 0.8195 - val_loss: 0.8563 - val_auc: 0.8686 - lr: 1.7783e-05\n",
      "Epoch 57/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 0.9934 - auc: 0.8241 - val_loss: 0.8556 - val_auc: 0.8692 - lr: 1.5849e-05\n",
      "Epoch 58/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 0.9986 - auc: 0.8226 - val_loss: 0.8531 - val_auc: 0.8704 - lr: 1.4125e-05\n",
      "Epoch 59/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 0.9918 - auc: 0.8252 - val_loss: 0.8538 - val_auc: 0.8697 - lr: 1.2589e-05\n",
      "Epoch 60/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0034 - auc: 0.8211 - val_loss: 0.8550 - val_auc: 0.8692 - lr: 1.1220e-05\n",
      "Epoch 61/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0089 - auc: 0.8195 - val_loss: 0.8527 - val_auc: 0.8701 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "191/191 [==============================] - 6s 33ms/step - loss: 1.0068 - auc: 0.8199 - val_loss: 0.8510 - val_auc: 0.8701 - lr: 8.9125e-06\n",
      "Epoch 63/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 0.9973 - auc: 0.8231 - val_loss: 0.8547 - val_auc: 0.8697 - lr: 7.9433e-06\n",
      "Epoch 64/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.0129 - auc: 0.8175 - val_loss: 0.8524 - val_auc: 0.8700 - lr: 7.0795e-06\n",
      "Epoch 65/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0033 - auc: 0.8209 - val_loss: 0.8519 - val_auc: 0.8708 - lr: 6.3096e-06\n",
      "Epoch 66/100\n",
      "191/191 [==============================] - 6s 32ms/step - loss: 1.0123 - auc: 0.8170 - val_loss: 0.8509 - val_auc: 0.8703 - lr: 5.6234e-06\n",
      "Epoch 67/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 0.9975 - auc: 0.8224 - val_loss: 0.8557 - val_auc: 0.8695 - lr: 5.0119e-06\n",
      "Epoch 68/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 0.9960 - auc: 0.8227 - val_loss: 0.8536 - val_auc: 0.8702 - lr: 4.4668e-06\n",
      "Epoch 69/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0102 - auc: 0.8191 - val_loss: 0.8532 - val_auc: 0.8701 - lr: 3.9811e-06\n",
      "Epoch 70/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 1.0054 - auc: 0.8206 - val_loss: 0.8547 - val_auc: 0.8693 - lr: 3.5481e-06\n",
      "Epoch 71/100\n",
      "191/191 [==============================] - 6s 31ms/step - loss: 0.9951 - auc: 0.8241 - val_loss: 0.8537 - val_auc: 0.8701 - lr: 3.1623e-06\n",
      "Epoch 72/100\n",
      "191/191 [==============================] - 6s 30ms/step - loss: 0.9955 - auc: 0.8228 - val_loss: 0.8536 - val_auc: 0.8697 - lr: 2.8184e-06\n",
      "Epoch 73/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0047 - auc: 0.8212 - val_loss: 0.8528 - val_auc: 0.8702 - lr: 2.5119e-06\n",
      "Epoch 74/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 1.0040 - auc: 0.8210 - val_loss: 0.8514 - val_auc: 0.8707 - lr: 2.2387e-06\n",
      "Epoch 75/100\n",
      "191/191 [==============================] - 6s 29ms/step - loss: 0.9946 - auc: 0.8235 - val_loss: 0.8541 - val_auc: 0.8701 - lr: 1.9953e-06\n",
      "Epoch 76/100\n",
      "191/191 [==============================] - 10s 52ms/step - loss: 1.0037 - auc: 0.8209 - val_loss: 0.8528 - val_auc: 0.8699 - lr: 1.7783e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data1,train_labels1,\n",
    "    validation_data=(val_data1, val_labels1),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "    epochs=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-30T11:32:39.336588Z",
     "iopub.status.busy": "2023-06-30T11:32:39.336091Z",
     "iopub.status.idle": "2023-06-30T11:32:40.241327Z",
     "shell.execute_reply": "2023-06-30T11:32:40.239611Z",
     "shell.execute_reply.started": "2023-06-30T11:32:39.336553Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.models' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.models' has no attribute 'load'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"alzheimer_model.h5\" , compile=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
